# gui_predict_one_race.py
# ------------------------------------------------------------
# 1ãƒ¬ãƒ¼ã‚¹æ¨è«– GUIï¼ˆapproach åˆ‡æ›¿ / ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ— or æ—¢å­˜CSV / CSVè‡ªå‹•æ¨å®š / åˆ—æƒ…å ±è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
#
# ãƒ•ãƒ­ãƒ¼ï¼ˆå¾“æ¥ï¼‰:
#   scrape_one_race -> build_live_row -> preprocess_course -> preprocess_sectional -> predict_one_race
#
# â˜…è¿½åŠ ï¼ˆ2026-02-02ã€œï¼‰
# - live CSV ã« motor ç‰¹å¾´é‡ã‚’ä»˜ä¸ã§ãã‚‹ã‚ˆã†ã€å­¦ç¿’ã¨åŒã˜2æ®µã‚’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¸æŒ¿å…¥ï¼š
#     1) preprocess_motor_id.py        : date/code/motor_number ã‹ã‚‰ motor_id ã‚’ä»˜ä¸
#     2) preprocess_motor_section.py   : motor_id + section_id ã§ motor_section_features ã‚’ joinï¼ˆmotor_åˆ—ã‚’è¿½åŠ ï¼‰
#
# - å …ç‰¢å„ªå…ˆï¼ˆé‹ç”¨ã‚µã‚¤ã‚¯ãƒ«åŒ–ã®ãŸã‚ã®æ–¹é‡ï¼‰ï¼š
#     - motor_id ä»˜ä¸ãŒå¤±æ•—ã—ãŸå ´åˆã€motor_section ã¯å®Ÿè¡Œã›ãšã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶™ç¶š
#     - motor_section ãŒå¤±æ•—ã—ãŸå ´åˆã‚‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶™ç¶š
#     - ãŸã ã—ãƒ­ã‚°ã«ã€Œmotor skippedï¼ˆç†ç”±ï¼‰ã€ã‚’æ˜è¨˜ã™ã‚‹
#
# - é‡è¦ï¼šlatestï¼ˆmotorç‰¹å¾´é‡ã‚ã‚Šï¼‰ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€motor_* åˆ—ãŒå…¥åŠ›ã«å­˜åœ¨ã—ãªã„ã¨
#         sklearn ColumnTransformer ãŒ transform æ™‚ã«ä¾‹å¤–ã‚’æŠ•ã’ã¦æ¨è«–ã§ããªã„ã€‚
#         ã—ãŸãŒã£ã¦ motor ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å ´åˆã§ã‚‚ã€motor_* åˆ—â€œã ã‘ã¯â€ NaN ã§ä½œæˆã—ã¦å…¥åŠ›ã¸è£œã†ã€‚
#         ï¼ˆå€¤ã¯ NaN ã®ã¾ã¾ã§OKã€‚å­¦ç¿’å´ã®è£œå®Œãƒ­ã‚¸ãƒƒã‚¯ or LightGBM ã®æ¬ ææ‰±ã„ã§å¸åã™ã‚‹æƒ³å®šï¼‰
#
# - é‡è¦ï¼šbuild_live_row.py ãŒ date åˆ—ã‚’ YYYYMMDDï¼ˆä¾‹: 20260202ï¼‰ã®å½¢ã§å‡ºã™å ´åˆãŒã‚ã‚‹ã€‚
#         preprocess_motor_id.py ã¯ pd.to_datetime() ã‚’ç´ ç›´ã«é©ç”¨ã™ã‚‹ãŸã‚ã€
#         æ•°å€¤ã® YYYYMMDD ãŒæ„å›³é€šã‚Šã€Œ2026-02-02ã€ã¨è§£é‡ˆã•ã‚Œãšã€æœŸé–“åˆ¤å®šãŒå…¨æ»…â†’motor_id 100%æ¬ æã«ãªã‚Šå¾—ã‚‹ã€‚
#         ãã®ãŸã‚ã€motor ã‚¹ãƒ†ãƒƒãƒ—ã®ç›´å‰ã§ date ã‚’ YYYY-MM-DD ã¸æ­£è¦åŒ–ã™ã‚‹ â€œæ¥µå°ã‚¹ãƒ†ãƒƒãƒ—â€ ã‚’è¿½åŠ ã™ã‚‹ã€‚
#         æ—§ãƒ¢ãƒ‡ãƒ«ï¼ˆmotorç„¡ã—ï¼‰ã§ã‚‚ date ã¯å­¦ç¿’ç‰¹å¾´é‡ã«ä½¿ã‚ã‚Œãªã„ãŸã‚ã€ã“ã®æ­£è¦åŒ–ã¯å®‰å…¨ã€‚
#
# - ãƒ­ã‚°æ°¸ç¶šåŒ–ï¼š
#     data/live/logs/gui_predict_YYYYMMDD_HHMMSS.log ã«è¿½è¨˜ä¿å­˜
# ------------------------------------------------------------

import os
import sys
import re
import json
import queue
import signal
import threading
import subprocess
import locale
from datetime import datetime, timezone, timedelta
from pathlib import Path
import tkinter as tk
from tkinter import ttk, filedialog, messagebox

# pandas ã¯ â€œdateæ­£è¦åŒ–â€ ã¨ â€œmotoråˆ—è£œå®Œâ€ ã®ãŸã‚ã«ä½¿ç”¨
# ï¼ˆGUIã®è¦‹ãŸç›®/æŒ™å‹•ã«ã¯å½±éŸ¿ã—ãªã„ï¼‰
import pandas as pd


# ====== å®šæ•° ======
APP_TITLE = "Boatrace 1ãƒ¬ãƒ¼ã‚¹æ¨è«– GUIï¼ˆbase/sectional + CSVè‡ªå‹•æ¨å®š + åˆ—ä¸€è¦§ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
SETTINGS_FILE = os.path.join("data", "config", "settings.json")
LEGACY_SETTINGS_FILE = "settings.json"  # æ—§äº’æ›

JCD_CHOICES  = [f"{i:02d}" for i in range(1, 25)]
RACE_CHOICES = [f"{i}" for i in range(1, 13)]
APPROACH_CHOICES = ["base", "sectional"]

# motor ã® live é‹ç”¨æ–¹é‡
# - mapæœªåæ˜ /äº¤æ›ç›´å¾Œãªã©ãŒã‚ã‚Šå¾—ã‚‹ãŸã‚ã€live ã¯ â€œè½ã¨ã•ãªã„â€ ã‚’å„ªå…ˆã™ã‚‹ã€‚
# - preprocess_motor_id.py ã® max_miss_rate ã¯ã€Œ%ï¼ˆ0ã€œ100ï¼‰ã€ã§è©•ä¾¡ã•ã‚Œã‚‹å®Ÿè£…ãªã®ã§ã€
#   live ã§ã¯ 100ï¼ˆ=100%æ¬ æã§ã‚‚è¨±å®¹ï¼‰ã«å¯„ã›ã‚‹ã€‚
#   â€» â€œæ¬ æã§ã‚‚è¨±å®¹â€ ã®ç›®çš„ã¯ã€Œæ¨è«–ã‚’æ­¢ã‚ãªã„ã€ã“ã¨ã€‚
#      latestãƒ¢ãƒ‡ãƒ«ã§ã¯åˆ—è£œå®Œã‚‚å¿…è¦ï¼ˆå¾Œè¿°ï¼‰ã€‚
LIVE_MOTOR_ID_MAX_MISS_RATE = 100.0

# motor_section ç‰¹å¾´é‡ï¼ˆå¸¸ã«æœ€æ–°ã‚’æƒ³å®šï¼‰
MOTOR_SECTION_FEATURES_CSV = os.path.join("data", "processed", "motor", "motor_section_features_n__all.csv")

# ãƒ­ã‚°ä¿å­˜å…ˆï¼ˆ1å®Ÿè¡Œ=1ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
LIVE_LOG_DIR = os.path.join("data", "live", "logs")

SCRIPTS = {
    "scrape_one_race": os.path.join("scripts", "scrape_one_race.py"),
    "build_live_row":  os.path.join("scripts", "build_live_row.py"),
    "predict_one_race": os.path.join("scripts", "predict_one_race.py"),
    "preprocess_course": os.path.join("scripts", "preprocess_course.py"),
    "preprocess_sectional": os.path.join("scripts", "preprocess_sectional.py"),

    # motor
    "preprocess_motor_id": os.path.join("scripts", "preprocess_motor_id.py"),
    "preprocess_motor_section": os.path.join("scripts", "preprocess_motor_section.py"),
}


# ====== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ======
def ensure_parent_dir(path: str):
    Path(path).parent.mkdir(parents=True, exist_ok=True)

def load_settings() -> dict:
    if os.path.exists(SETTINGS_FILE):
        try:
            with open(SETTINGS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    if os.path.exists(LEGACY_SETTINGS_FILE):
        try:
            with open(LEGACY_SETTINGS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            ensure_parent_dir(SETTINGS_FILE)
            with open(SETTINGS_FILE, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return data
        except Exception:
            return {}
    return {}

def save_settings(state: dict):
    try:
        ensure_parent_dir(SETTINGS_FILE)
        with open(SETTINGS_FILE, "w", encoding="utf-8") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def today_jst_yyyymmdd() -> str:
    jst = timezone(timedelta(hours=9))
    return datetime.now(jst).strftime("%Y%m%d")

def valid_yyyymmdd(s: str) -> bool:
    if not s or len(s) != 8 or not s.isdigit():
        return False
    try:
        datetime.strptime(s, "%Y%m%d")
        return True
    except ValueError:
        return False

def now_jst_timestamp() -> str:
    jst = timezone(timedelta(hours=9))
    return datetime.now(jst).strftime("%Y%m%d_%H%M%S")


# ====== è¿½åŠ ï¼šdate æ­£è¦åŒ–ï¼ˆYYYYMMDD â†’ YYYY-MM-DDï¼‰ ======
def normalize_date_column_inplace(csv_path: str, log_fn=None) -> bool:
    """
    live CSV ã® date åˆ—ã‚’æ­£è¦åŒ–ã™ã‚‹ï¼ˆæ¥µå°ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
    - build_live_row.py ãŒ date=YYYYMMDDï¼ˆä¾‹: 20260202ï¼‰ã‚’å‡ºã™ã‚±ãƒ¼ã‚¹ã‚’å¸åã™ã‚‹
    - preprocess_motor_id.py ã¯ pd.to_datetime() ã‚’ç´ ç›´ã«é©ç”¨ã™ã‚‹ãŸã‚ã€
      æ•°å€¤YYYYMMDDã‚’æ„å›³é€šã‚Šè§£é‡ˆã§ããªã„ã‚±ãƒ¼ã‚¹ãŒã‚ã‚‹ã€‚
    - æ—§ãƒ¢ãƒ‡ãƒ«ã¯ date ã‚’ç‰¹å¾´é‡ã«ä½¿ã‚ãªã„ãŸã‚ã€ã“ã®æ­£è¦åŒ–ã¯å®‰å…¨ã€‚

    æŒ™å‹•ï¼š
    - date åˆ—ãŒå­˜åœ¨ã—ãªã„ â†’ ä½•ã‚‚ã—ãªã„ï¼ˆFalseï¼‰
    - date ã®å…ˆé ­å€¤ãŒ YYYY-MM-DD ã£ã½ã„ â†’ ä½•ã‚‚ã—ãªã„ï¼ˆTrueï¼‰
    - date ãŒ 8æ¡æ•°å­—ãªã‚‰ format=%Y%m%d ã§ãƒ‘ãƒ¼ã‚¹ã— YYYY-MM-DD ã«å¤‰æ›
    - å¤‰æ›ã«å¤±æ•—ï¼ˆNaTãŒç™ºç”Ÿï¼‰ã—ãŸå ´åˆã‚‚â€œæ¨è«–ã¯æ­¢ã‚ãªã„â€æ–¹é‡ã®ãŸã‚ã€å…ƒã®å€¤ã‚’æ®‹ã—ã¤ã¤ WARN ã‚’å‡ºã™

    Returns:
        True  : å‡¦ç†ã‚’è©¦ã¿ãŸï¼ˆå¤‰æ›ã—ãŸ/ã—ãªã‹ã£ãŸå«ã‚€ï¼‰
        False : dateåˆ—ãŒç„¡ãã€ä½•ã‚‚ã—ãªã‹ã£ãŸ
    """
    if not os.path.exists(csv_path):
        if log_fn:
            log_fn(f"[WARN] date normalize skipped: file not found: {csv_path}")
        return False

    try:
        df = pd.read_csv(csv_path, low_memory=False)
    except Exception as e:
        if log_fn:
            log_fn(f"[WARN] date normalize skipped: read failed: {e}")
        return False

    if "date" not in df.columns:
        if log_fn:
            log_fn("[INFO] date normalize: no 'date' column (skipped)")
        return False

    # å…ˆé ­å€¤ã§ã–ã£ãã‚Šåˆ¤å®šï¼ˆå…¨è¡ŒåŒå½¢å¼ã§å‡ºã‚‹æƒ³å®šï¼‰
    head = df["date"].iloc[0]
    s_head = "" if pd.isna(head) else str(head).strip()

    # æ—¢ã« YYYY-MM-DD ãªã‚‰ä½•ã‚‚ã—ãªã„
    if re.fullmatch(r"\d{4}-\d{2}-\d{2}", s_head):
        if log_fn:
            log_fn(f"[INFO] date normalize: already ISO (sample={s_head})")
        return True

    # 8æ¡æ•°å­—ï¼ˆYYYYMMDDï¼‰ã¨ã—ã¦è§£é‡ˆã§ãã‚‹ã‚‚ã®ã¯å¤‰æ›ã™ã‚‹
    # â€» float ã«ãªã£ã¦ "20260202.0" ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã‚±ãƒ¼ã‚¹ã‚‚ã‚ã‚‹ã®ã§ .0 ã‚’é™¤å»
    s = df["date"].astype(str).str.strip().str.replace(r"\.0$", "", regex=True)

    is_yyyymmdd_like = s.str.fullmatch(r"\d{8}", na=False)
    if is_yyyymmdd_like.any():
        # è©²å½“è¡Œã ã‘å¤‰æ›ï¼ˆä»–ã¯ãã®ã¾ã¾ï¼‰
        parsed = pd.to_datetime(s.where(is_yyyymmdd_like, pd.NA), format="%Y%m%d", errors="coerce")
        # å¤‰æ›ã§ããŸè¡Œã®ã¿ YYYY-MM-DD ã¸
        iso = parsed.dt.strftime("%Y-%m-%d")

        # å¤±æ•—è¡Œï¼ˆcoerceâ†’NaTï¼‰ãŒã‚ã‚‹å ´åˆã§ã‚‚æ­¢ã‚ãªã„ï¼ˆå …ç‰¢å„ªå…ˆï¼‰
        bad = iso.isna() & is_yyyymmdd_like
        if bad.any() and log_fn:
            n_bad = int(bad.sum())
            log_fn(f"[WARN] date normalize: failed to parse {n_bad} rows as YYYYMMDD (kept original)")

        # åæ˜ ï¼ˆæˆåŠŸã—ãŸè¡Œã ã‘ä¸Šæ›¸ãï¼‰
        df.loc[iso.notna(), "date"] = iso[iso.notna()]

        # ä¸Šæ›¸ãä¿å­˜ï¼ˆutf-8-sig ã‚’ç¶­æŒï¼‰
        df.to_csv(csv_path, index=False, encoding="utf-8-sig")

        if log_fn:
            # å¤‰æ›å¾Œã®å…ˆé ­ã‚’å†è¡¨ç¤º
            sample2 = str(df["date"].iloc[0])
            log_fn(f"[INFO] date normalize: converted (sample={s_head} -> {sample2})")
        return True

    # ã“ã“ã¾ã§æ¥ãŸã‚‰ â€œ8æ¡æ•°å­—ã§ã¯ãªã„ãŒ ISOã§ã‚‚ãªã„â€ å½¢å¼
    # motor_id ä»˜ä¸ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ã¯ã‚ã‚‹ãŒã€GUIå´ã§å‹æ‰‹ã«å¤‰å½¢ã™ã‚‹ã¨å±é™ºãªã®ã§ã“ã“ã§ã¯è§¦ã‚‰ãªã„ã€‚
    if log_fn:
        log_fn(f"[WARN] date normalize: unknown format (sample={s_head}) (left as-is)")
    return True


# ====== è¿½åŠ ï¼šmotoråˆ—ã®è£œå®Œï¼ˆmotorã‚¹ã‚­ãƒƒãƒ—æ™‚ã«åˆ—åã ã‘æƒãˆã‚‹ï¼‰ ======
def ensure_motor_feature_columns_inplace(csv_path: str, motor_features_csv: str, log_fn=None) -> bool:
    """
    motor step ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå ´åˆã§ã‚‚ã€latestï¼ˆmotorã‚ã‚Šï¼‰ãƒ¢ãƒ‡ãƒ«ã§ transform ãŒè½ã¡ãªã„ã‚ˆã†ã«ã€
    motor_* åˆ—ã‚’ NaN åˆ—ã¨ã—ã¦è£œå®Œã™ã‚‹ã€‚

    - motor_section_features_n__all.csv ã® â€œç‰¹å¾´é‡åˆ—â€ ã‚’èª­ã¿å–ã‚Šã€
      live CSV ã«ç„¡ã„åˆ—ã¯ motor_ æ¥é ­è¾ä»˜ãã§è¿½åŠ ï¼ˆå€¤ã¯ NaNï¼‰
    - æ—¢ã«å­˜åœ¨ã™ã‚‹åˆ—ã¯è§¦ã‚‰ãªã„

    Returns:
        True  : è£œå®Œã‚’å®Ÿæ–½/ç¢ºèªã—ãŸ
        False : motor_features_csv ãŒå­˜åœ¨ã—ãªã„ç­‰ã§ä½•ã‚‚ã—ãªã‹ã£ãŸ
    """
    if not os.path.exists(csv_path):
        if log_fn:
            log_fn(f"[WARN] motor col fill skipped: live csv not found: {csv_path}")
        return False
    if not os.path.exists(motor_features_csv):
        if log_fn:
            log_fn(f"[WARN] motor col fill skipped: motor features not found: {motor_features_csv}")
        return False

    try:
        df_live = pd.read_csv(csv_path, low_memory=False)
    except Exception as e:
        if log_fn:
            log_fn(f"[WARN] motor col fill skipped: read live failed: {e}")
        return False

    try:
        # ãƒ˜ãƒƒãƒ€ã ã‘èª­ã‚€ï¼ˆé«˜é€Ÿï¼‰
        df_feat0 = pd.read_csv(motor_features_csv, nrows=0)
        feat_cols = list(df_feat0.columns)
    except Exception as e:
        if log_fn:
            log_fn(f"[WARN] motor col fill skipped: read motor header failed: {e}")
        return False

    # motor_section_features å´ã® â€œã‚­ãƒ¼ãƒ»ãƒ¡ã‚¿åˆ—â€ ã¯é™¤å¤–ã—ã¦ã€æ®‹ã‚Šã‚’ç‰¹å¾´é‡æ‰±ã„ã«ã™ã‚‹
    # â€» å®Ÿãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦å¢—æ¸›ã—ã¦ã‚‚å£Šã‚Œã«ãã„ã‚ˆã†ã€ä¿å®ˆçš„ã«é™¤å¤–ã™ã‚‹ã€‚
    meta_like = {
        "code", "motor_number", "idx_motor", "motor_id",
        "section_id", "section_start_dt", "section_end_dt",
        "effective_from", "effective_to",
    }
    raw_feature_cols = [c for c in feat_cols if c not in meta_like]

    # live å´ã«è¿½åŠ ã™ã¹ãåˆ—åï¼ˆæ¥é ­è¾ motor_ï¼‰
    need_cols = [f"motor_{c}" for c in raw_feature_cols]

    missing = [c for c in need_cols if c not in df_live.columns]
    if not missing:
        if log_fn:
            log_fn(f"[INFO] motor col fill: OK (no missing motor_* cols) cols={len(need_cols)}")
        return True

    # æ¬ ã‘ã¦ã„ã‚‹ motor_* åˆ—ã‚’ NaN ã§è¿½åŠ 
    for c in missing:
        df_live[c] = pd.NA

    # ä¿å­˜ï¼ˆä¸Šæ›¸ãï¼‰
    df_live.to_csv(csv_path, index=False, encoding="utf-8-sig")

    if log_fn:
        log_fn(f"[INFO] motor col fill: added {len(missing)} cols as NaN (total motor feat cols={len(need_cols)})")
    return True


# ====== å®Ÿè¡Œãƒ©ãƒ³ãƒŠãƒ¼ ======
class Runner:
    def __init__(self, log_queue: queue.Queue):
        self.log_queue = log_queue
        self.stop_flag = threading.Event()
        self.current_proc = None
        self.log_file_path = None

    def _log(self, text: str):
        """GUIãƒ­ã‚°ï¼ˆqueueï¼‰ã¸é€ã‚‹ã€‚å¿…è¦ãªã‚‰ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚è¿½è¨˜ã™ã‚‹ã€‚"""
        self.log_queue.put(text)
        if self.log_file_path:
            try:
                ensure_parent_dir(self.log_file_path)
                with open(self.log_file_path, "a", encoding="utf-8", errors="replace") as f:
                    f.write(text + "\n")
            except Exception:
                pass

    def stop(self):
        self.stop_flag.set()
        try:
            if self.current_proc and self.current_proc.poll() is None:
                if os.name == "nt":
                    self.current_proc.send_signal(signal.CTRL_BREAK_EVENT)
                self.current_proc.terminate()
        except Exception:
            pass

    def _run_and_stream(self, cmd, cwd=None, env=None):
        """ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•ã— stdout/stderr ã‚’é€æ¬¡GUIã¸æµã™ã€‚"""
        if self.stop_flag.is_set():
            return 1
        enc = locale.getpreferredencoding(False)
        self._log(f"\n$ {' '.join(map(str, cmd))}\n")

        creationflags = subprocess.CREATE_NEW_PROCESS_GROUP if os.name == "nt" else 0
        preexec_fn = None
        if os.name != "nt":
            import os as _os
            preexec_fn = _os.setsid

        self.current_proc = subprocess.Popen(
            cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
            text=True, bufsize=1, universal_newlines=True,
            encoding=enc, errors="replace",
            creationflags=creationflags, preexec_fn=preexec_fn,
            env=env
        )

        for raw in self.current_proc.stdout:
            line = (raw or "").rstrip("\n")
            self._log(line)

        rc = self.current_proc.wait()
        self.current_proc = None
        self._log(f"[exit code] {rc}\n")
        return rc

    def run_pipeline(self,
                     date_yyyymmdd: str, jcd: str, race: str,
                     approach: str, model_dir: str,
                     use_online: bool,
                     use_csv: bool, csv_path: str, csv_autoguess: bool,
                     show_features: bool,
                     repo_root: str,
                     dump_debug: bool = False):

        # ã“ã®å®Ÿè¡Œã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºå®š
        self.log_file_path = os.path.join(LIVE_LOG_DIR, f"gui_predict_{now_jst_timestamp()}.log")
        self._log(f"[INFO] log file: {self.log_file_path}")

        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆmotorè¿½åŠ åˆ†å«ã‚€ï¼‰
        for k in ("scrape_one_race","build_live_row","predict_one_race",
                  "preprocess_course","preprocess_sectional",
                  "preprocess_motor_id","preprocess_motor_section"):
            if k in SCRIPTS and not os.path.exists(SCRIPTS[k]):
                self._log(f"ERROR: {SCRIPTS[k]} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒªãƒã‚¸ãƒˆãƒªç›´ä¸‹ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                return

        # 1) å…¥åŠ›CSVã‚’æ±ºã‚ã‚‹
        in_csv = None
        if use_csv:
            if csv_autoguess:
                guessed = os.path.join("data","live", f"raw_{date_yyyymmdd}_{jcd}_{race}.csv")
                if os.path.exists(guessed):
                    in_csv = guessed
                    self._log(f"[INFO] CSVè‡ªå‹•æ¨å®š: {guessed}")
                else:
                    self._log(f"[WARN] CSVè‡ªå‹•æ¨å®š: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ -> {guessed}")
                    if csv_path and os.path.exists(csv_path):
                        in_csv = csv_path
                        self._log(f"[INFO] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ˜ç¤ºæŒ‡å®šCSVã‚’ä½¿ç”¨ -> {csv_path}")
                    else:
                        self._log("[ERROR] å…¥åŠ›CSVãŒç¢ºå®šã§ãã¾ã›ã‚“ï¼ˆè‡ªå‹•æ¨å®šå¤±æ•—ã‹ã¤æ˜ç¤ºæŒ‡å®šãªã—/ä¸åœ¨ï¼‰")
                        return
            else:
                if not csv_path or not os.path.exists(csv_path):
                    self._log("[ERROR] æ—¢å­˜CSVã‚’ä½¿ç”¨ã«ãƒã‚§ãƒƒã‚¯ã‚ã‚Šã§ã™ãŒã€CSVãƒ‘ã‚¹ãŒä¸æ­£ã§ã™ã€‚")
                    return
                in_csv = csv_path
                self._log(f"[INFO] æ˜ç¤ºæŒ‡å®šCSVã‚’ä½¿ç”¨: {csv_path}")
        else:
            # 2) scrape
            rc = self._run_and_stream(
                [sys.executable, SCRIPTS["scrape_one_race"], "--date", date_yyyymmdd, "--jcd", jcd, "--race", race],
                cwd=repo_root
            )
            if rc != 0 or self.stop_flag.is_set():
                return

            # 3) build_live_row
            out_csv = os.path.join("data","live", f"raw_{date_yyyymmdd}_{jcd}_{race}.csv")
            cmd2 = [sys.executable, SCRIPTS["build_live_row"],
                    "--date", date_yyyymmdd, "--jcd", jcd, "--race", race, "--out", out_csv]
            if use_online:
                cmd2.append("--online")
            rc = self._run_and_stream(cmd2, cwd=repo_root)
            if rc != 0 or self.stop_flag.is_set():
                return
            in_csv = out_csv

        if not in_csv:
            self._log("[ERROR] å†…éƒ¨ã‚¨ãƒ©ãƒ¼: in_csv ãŒæœªç¢ºå®šã§ã™ã€‚")
            return

        # ---------------------------------------------------------------------
        # â˜…è¿½åŠ ï¼šdate æ­£è¦åŒ–ï¼ˆYYYYMMDD â†’ YYYY-MM-DDï¼‰
        # - motor_id ä»˜ä¸ã®å‰æã‚’æº€ãŸã™ãŸã‚ã€ã“ã“ã§å¿…ãšä¸€åº¦æ­£è¦åŒ–ã‚’è©¦ã¿ã‚‹
        # - æ—§ãƒ¢ãƒ‡ãƒ«ã§ã‚‚å®‰å…¨ï¼ˆdate ã‚’ç‰¹å¾´é‡ã«ä½¿ã‚ãªã„æƒ³å®šï¼‰
        # ---------------------------------------------------------------------
        normalize_date_column_inplace(in_csv, log_fn=self._log)

        # ---------------------------------------------------------------------
        # â˜…motor ç‰¹å¾´é‡ï¼ˆå­¦ç¿’ã¨åŒã˜2æ®µã‚’ live CSV ã«ä¸Šæ›¸ãä»˜ä¸ï¼‰
        # - preprocess_motor_id.py      : date/code/motor_number ã‹ã‚‰ motor_id ã‚’ä»˜ä¸
        # - preprocess_motor_section.py : motor_id + section_id ã§ motor_section_features ã‚’ joinï¼ˆmotor_åˆ—ã‚’è¿½åŠ ï¼‰
        #
        # å …ç‰¢å„ªå…ˆã®é‹ç”¨æ–¹é‡ï¼š
        # - motor ãŒè½ã¡ã¦ã‚‚æ¨è«–ã‚’æ­¢ã‚ãªã„
        # - ãŸã ã— latestï¼ˆmotorã‚ã‚Šï¼‰ãƒ¢ãƒ‡ãƒ«ã¯åˆ—ä¸è¶³ã§è½ã¡ã‚‹ãŸã‚ã€motor_* åˆ—ã‚’ NaN ã§è£œå®Œã™ã‚‹
        # ---------------------------------------------------------------------
        motor_enabled = True
        motor_skip_reason = ""

        # (A) motor_id ä»˜ä¸ï¼ˆliveã¯è½ã¨ã•ãªã„ï¼šmax_miss_rate=100%ï¼‰
        cmd_m1 = [
            sys.executable, SCRIPTS["preprocess_motor_id"],
            "--in_csv", in_csv,
            "--out_csv", in_csv,  # ä¸Šæ›¸ã
            "--max_miss_rate", str(LIVE_MOTOR_ID_MAX_MISS_RATE),
        ]
        rc = self._run_and_stream(cmd_m1, cwd=repo_root)
        if rc != 0 or self.stop_flag.is_set():
            motor_enabled = False
            motor_skip_reason = f"preprocess_motor_id failed (exit={rc})"
            if self.stop_flag.is_set():
                return
            self._log(f"[WARN] motor skipped: {motor_skip_reason}")
        else:
            # (B) motor_section join
            if not os.path.exists(MOTOR_SECTION_FEATURES_CSV):
                motor_enabled = False
                motor_skip_reason = f"motor_section_features not found: {MOTOR_SECTION_FEATURES_CSV}"
                self._log(f"[WARN] motor skipped: {motor_skip_reason}")
            else:
                cmd_m2 = [
                    sys.executable, SCRIPTS["preprocess_motor_section"],
                    "--master_csv", in_csv,
                    "--motor_section_csv", MOTOR_SECTION_FEATURES_CSV,
                    "--out_master_csv", in_csv,  # ä¸Šæ›¸ã
                ]
                rc2 = self._run_and_stream(cmd_m2, cwd=repo_root)
                if rc2 != 0 or self.stop_flag.is_set():
                    motor_enabled = False
                    motor_skip_reason = f"preprocess_motor_section failed (exit={rc2})"
                    if self.stop_flag.is_set():
                        return
                    self._log(f"[WARN] motor skipped: {motor_skip_reason}")
                else:
                    self._log("[INFO] motor features: OK (motor_id + motor_section joined)")

        # motor ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå ´åˆã§ã‚‚ã€latestï¼ˆmotorã‚ã‚Šï¼‰ãƒ¢ãƒ‡ãƒ«ã§è½ã¡ãªã„ã‚ˆã†åˆ—ã ã‘è£œå®Œã™ã‚‹
        if not motor_enabled:
            ensure_motor_feature_columns_inplace(
                in_csv,
                motor_features_csv=MOTOR_SECTION_FEATURES_CSV,
                log_fn=self._log
            )

        # ---------------------------------------------------------------------
        # preprocess_course / preprocess_sectionalï¼ˆå¾“æ¥ãƒ•ãƒ­ãƒ¼ï¼‰
        # ---------------------------------------------------------------------
        DEFAULT_WARMUP_DAYS = 180
        DEFAULT_N_LAST = 10

        # YYYYMMDD â†’ YYYY-MM-DD
        y, m, d = date_yyyymmdd[:4], date_yyyymmdd[4:6], date_yyyymmdd[6:]
        start_str = f"{y}-{m}-{d}"
        end_str   = f"{y}-{m}-{d}"

        reports_dir = os.path.join("data", "processed", "course_meta_live")
        ensure_parent_dir(os.path.join(reports_dir, "_dummy.txt"))

        cmd_pc = [
            sys.executable, SCRIPTS["preprocess_course"],
            "--master", in_csv,
            "--raw-dir", os.path.join("data", "raw"),
            "--out", in_csv,
            "--reports-dir", reports_dir,
            "--start-date", start_str,
            "--end-date",   end_str,
            "--warmup-days", str(DEFAULT_WARMUP_DAYS),
            "--n-last",       str(DEFAULT_N_LAST),
        ]
        rc = self._run_and_stream(cmd_pc, cwd=repo_root)
        if rc != 0 or self.stop_flag.is_set():
            return

        cmd_ps = [
            sys.executable, SCRIPTS["preprocess_sectional"],
            "--master", in_csv,
            "--raceinfo-dir", os.path.join("data", "processed", "raceinfo"),
            "--date", date_yyyymmdd,
            "--live-html-root", os.path.join("data","live","html"),
            "--out", in_csv
        ]
        rc = self._run_and_stream(cmd_ps, cwd=repo_root)
        if rc != 0 or self.stop_flag.is_set():
            return

        # ---------------------------------------------------------------------
        # ãƒ¢ãƒ‡ãƒ«DIRï¼ˆæœªæŒ‡å®šãªã‚‰ models/<approach>/latestï¼‰
        # ---------------------------------------------------------------------
        if not model_dir:
            model_dir = os.path.join("models", approach, "latest")
        model_pkl = os.path.join(model_dir, "model.pkl")
        feat_pkl  = os.path.join(model_dir, "feature_pipeline.pkl")
        if not os.path.exists(model_pkl) or not os.path.exists(feat_pkl):
            self._log(f"ERROR: {approach} ãƒ¢ãƒ‡ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚\n  model: {model_pkl}\n  feature_pipeline: {feat_pkl}")
            return

        # ---------------------------------------------------------------------
        # predict_one_raceï¼ˆãƒ‡ãƒãƒƒã‚°CSVå‡ºåŠ›ã¯ç’°å¢ƒå¤‰æ•°ã§ON/OFFï¼‰
        # ---------------------------------------------------------------------
        cmd3 = [sys.executable, SCRIPTS["predict_one_race"],
                "--live-csv", in_csv,
                "--approach", approach,
                "--model", model_pkl,
                "--feature-pipeline", feat_pkl]
        if show_features:
            cmd3.append("--show-features")

        env3 = None
        if dump_debug:
            env3 = os.environ.copy()
            env3["ADAPTER_DUMP_CSV"] = os.path.join("data", "live", "_debug_merged.csv")
            env3["ADAPTER_DUMP_STEPS"] = "1"

        rc = self._run_and_stream(cmd3, cwd=repo_root, env=env3)
        if rc != 0 or self.stop_flag.is_set():
            return

        # æœ€çµ‚ã‚µãƒãƒªï¼ˆé‹ç”¨ãƒ­ã‚°å‘ã‘ï¼‰
        self._log("------------------------------------------------------------")
        self._log(f"[SUMMARY] in_csv={in_csv}")
        self._log(f"[SUMMARY] approach={approach}")
        self._log(f"[SUMMARY] model_dir={model_dir}")
        if motor_enabled:
            self._log("[SUMMARY] motor=OK")
        else:
            self._log(f"[SUMMARY] motor=SKIPPED reason={motor_skip_reason}")
        self._log("------------------------------------------------------------")

        self._log("\n=== ã™ã¹ã¦å®Œäº†ã—ã¾ã—ãŸ âœ… ===\n")


# ====== GUIæœ¬ä½“ ======
class App(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title(APP_TITLE)
        self.geometry("1020x760")
        self.settings = load_settings()

        # å…¥åŠ›å€¤
        self.var_date  = tk.StringVar(value=self.settings.get("date", today_jst_yyyymmdd()))
        self.var_jcd   = tk.StringVar(value=self.settings.get("jcd", "24"))
        self.var_race  = tk.StringVar(value=self.settings.get("race","12"))
        self.var_approach = tk.StringVar(value=self.settings.get("approach","base"))

        # å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæ—¢å­˜ï¼‰
        self.var_use_csv        = tk.BooleanVar(value=self.settings.get("use_csv", False))
        self.var_csv_autoguess  = tk.BooleanVar(value=self.settings.get("csv_autoguess", True))
        self.var_csv_path       = tk.StringVar(value=self.settings.get("csv_path",""))
        self.var_show_features  = tk.BooleanVar(value=self.settings.get("show_features", False))
        self.var_dump_debug     = tk.BooleanVar(value=self.settings.get("dump_debug", False))

        # è©³ç´°è¨­å®š
        self.var_advanced = tk.BooleanVar(value=False)  # èµ·å‹•æ™‚ã¯è¡¨ç¤ºOFF
        self.var_online   = tk.BooleanVar(value=self.settings.get("use_online", False))

        # ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã”ã¨ã«ãƒ¢ãƒ‡ãƒ«DIRã‚’ä¿æŒ
        self.var_model_dir  = tk.StringVar(value=self.settings.get("model_dir_base", os.path.join("models","base","latest")))
        self.var_model_dir_map = {
            "base": self.settings.get("model_dir_base", os.path.join("models","base","latest")),
            "sectional": self.settings.get("model_dir_sectional", os.path.join("models","sectional","latest")),
        }

        # ãƒ­ã‚°
        self.log_queue = queue.Queue()
        self.runner = Runner(self.log_queue)

        self._build_ui()
        self.after(50, self._poll_log_queue)

    def _build_ui(self):
        frm_in = ttk.LabelFrame(self, text="å…¥åŠ›"); frm_in.pack(fill=tk.X, padx=10, pady=(10,6))
        ttk.Label(frm_in, text="æ—¥ä»˜(YYYYMMDD)").grid(row=0, column=0, sticky="w")
        ttk.Entry(frm_in, textvariable=self.var_date, width=12).grid(row=0, column=1, padx=(5,15))
        ttk.Label(frm_in, text="å ´ã‚³ãƒ¼ãƒ‰").grid(row=0, column=2, sticky="w")
        ttk.Combobox(frm_in, textvariable=self.var_jcd, values=JCD_CHOICES, width=6, state="readonly").grid(row=0, column=3, padx=(5,15))
        ttk.Label(frm_in, text="ãƒ¬ãƒ¼ã‚¹").grid(row=0, column=4, sticky="w")
        ttk.Combobox(frm_in, textvariable=self.var_race, values=RACE_CHOICES, width=6, state="readonly").grid(row=0, column=5, padx=(5,15))
        ttk.Label(frm_in, text="ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ").grid(row=0, column=6, sticky="w")
        cmb = ttk.Combobox(frm_in, textvariable=self.var_approach, values=APPROACH_CHOICES, width=10, state="readonly")
        cmb.grid(row=0, column=7, padx=(5,15))
        cmb.bind("<<ComboboxSelected>>", self._on_change_approach)

        frm_btn = ttk.Frame(self); frm_btn.pack(fill=tk.X, padx=10, pady=6)
        self.btn_run  = ttk.Button(frm_btn, text="â–¶ æ¨è«–é–‹å§‹", command=self.on_run, width=20); self.btn_run.pack(side=tk.LEFT)
        self.btn_stop = ttk.Button(frm_btn, text="â–  åœæ­¢", command=self.on_stop, width=10, state=tk.DISABLED); self.btn_stop.pack(side=tk.LEFT, padx=6)
        ttk.Checkbutton(frm_btn, text="æ—¢å­˜CSVã‹ã‚‰æ¨è«–", variable=self.var_use_csv).pack(side=tk.LEFT, padx=(18,8))
        ttk.Checkbutton(frm_btn, text="CSVè‡ªå‹•æ¨å®š", variable=self.var_csv_autoguess).pack(side=tk.LEFT, padx=(0,12))
        ttk.Checkbutton(frm_btn, text="åˆ—æƒ…å ±ã‚’è¡¨ç¤º (--show-features)", variable=self.var_show_features).pack(side=tk.LEFT, padx=(0,12))
        ttk.Checkbutton(frm_btn, text="ãƒ‡ãƒãƒƒã‚°CSVå‡ºåŠ› (_debug_merged.csv)", variable=self.var_dump_debug).pack(side=tk.LEFT, padx=(0,12))
        ttk.Button(frm_btn, text="ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆdata/liveï¼‰", command=self._open_live_dir).pack(side=tk.RIGHT)

        frm_csv = ttk.Frame(self); frm_csv.pack(fill=tk.X, padx=10, pady=(0,6))
        ttk.Label(frm_csv, text="CSVãƒ‘ã‚¹").pack(side=tk.LEFT)
        ttk.Entry(frm_csv, textvariable=self.var_csv_path).pack(side=tk.LEFT, fill=tk.X, expand=True, padx=6)
        ttk.Button(frm_csv, text="å‚ç…§", command=self._browse_csv).pack(side=tk.LEFT)

        self.frm_adv = ttk.LabelFrame(self, text="è©³ç´°è¨­å®šï¼ˆãƒ¢ãƒ‡ãƒ«/å®Ÿé¨“ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
        ttk.Label(self.frm_adv, text="ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆé¸æŠã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«å¯¾å¿œï¼‰").grid(row=0, column=0, sticky="w")
        ttk.Entry(self.frm_adv, textvariable=self.var_model_dir).grid(row=0, column=1, sticky="we", padx=6)
        ttk.Button(self.frm_adv, text="å‚ç…§", command=self._browse_model_dir).grid(row=0, column=2, padx=6)
        self.frm_adv.columnconfigure(1, weight=1)
        ttk.Checkbutton(self.frm_adv, text="build_live_row ã« --onlineï¼ˆæ¤œè¨¼/éå¸¸æ™‚ã®ã¿ã€‚é€šå¸¸ã¯OFFï¼‰",
                        variable=self.var_online).grid(row=1, column=0, columnspan=3, sticky="w", pady=(6,0))

        frm_toggle = ttk.Frame(self); frm_toggle.pack(fill=tk.X, padx=10, pady=(0,6))
        ttk.Checkbutton(frm_toggle, text="è©³ç´°è¨­å®šã‚’è¡¨ç¤º", variable=self.var_advanced, command=self._toggle_adv).pack(side=tk.LEFT)

        frm_log = ttk.LabelFrame(self, text="ãƒ­ã‚°"); frm_log.pack(fill=tk.BOTH, expand=True, padx=10, pady=(6,10))
        self.txt_log = tk.Text(frm_log, wrap="word", height=24)
        self.txt_log.pack(fill=tk.BOTH, expand=True)

    def _browse_csv(self):
        f = filedialog.askopenfilename(filetypes=[("CSV files", "*.csv")])
        if f:
            self.var_csv_path.set(f)

    def _browse_model_dir(self):
        d = filedialog.askdirectory(title=f"{self.var_approach.get()} ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", initialdir=os.getcwd())
        if d:
            self.var_model_dir.set(d)
            self.var_model_dir_map[self.var_approach.get()] = d

    def _toggle_adv(self):
        if self.var_advanced.get():
            self.frm_adv.pack(fill=tk.X, padx=10, pady=(0,6))
        else:
            self.frm_adv.forget()

    def _open_live_dir(self):
        live_dir = os.path.join("data","live")
        Path(live_dir).mkdir(parents=True, exist_ok=True)
        if os.name == "nt":
            os.startfile(live_dir)
        elif sys.platform == "darwin":
            subprocess.Popen(["open", live_dir])
        else:
            subprocess.Popen(["xdg-open", live_dir])

    def _on_change_approach(self, _evt=None):
        ap = self.var_approach.get()
        d = self.var_model_dir_map.get(ap, os.path.join("models", ap, "latest"))
        self.var_model_dir.set(d)

    def on_run(self):
        date = self.var_date.get().strip()
        jcd  = self.var_jcd.get().strip()
        race = self.var_race.get().strip()
        approach = self.var_approach.get().strip()
        model_dir = self.var_model_dir.get().strip()

        use_csv       = bool(self.var_use_csv.get())
        csv_autoguess = bool(self.var_csv_autoguess.get())
        csv_path      = self.var_csv_path.get().strip()
        show_features = bool(self.var_show_features.get())
        use_online    = bool(self.var_online.get())
        dump_debug    = bool(self.var_dump_debug.get())

        if not valid_yyyymmdd(date):
            messagebox.showerror("å…¥åŠ›ã‚¨ãƒ©ãƒ¼","æ—¥ä»˜ã¯ YYYYMMDD ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        if jcd not in JCD_CHOICES:
            messagebox.showerror("å…¥åŠ›ã‚¨ãƒ©ãƒ¼","å ´ã‚³ãƒ¼ãƒ‰ãŒä¸æ­£ã§ã™ã€‚")
            return
        try:
            r = int(race)
            assert 1 <= r <= 12
        except Exception:
            messagebox.showerror("å…¥åŠ›ã‚¨ãƒ©ãƒ¼","ãƒ¬ãƒ¼ã‚¹ç•ªå·ã¯ 1ã€œ12 ã®æ•´æ•°ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        if approach not in APPROACH_CHOICES:
            messagebox.showerror("å…¥åŠ›ã‚¨ãƒ©ãƒ¼","ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒä¸æ­£ã§ã™ã€‚")
            return
        for p in SCRIPTS.values():
            if not os.path.exists(p):
                messagebox.showerror("ãƒ•ã‚¡ã‚¤ãƒ«ãªã—", f"{p} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒªãƒã‚¸ãƒˆãƒªç›´ä¸‹ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                return

        # è¨­å®šä¿å­˜
        self.var_model_dir_map[approach] = model_dir
        save_settings({
            "date": date, "jcd": jcd, "race": race,
            "approach": approach,
            "use_csv": use_csv,
            "csv_autoguess": csv_autoguess,
            "csv_path": csv_path,
            "show_features": show_features,
            "dump_debug": dump_debug,
            "model_dir_base": self.var_model_dir_map.get("base", os.path.join("models","base","latest")),
            "model_dir_sectional": self.var_model_dir_map.get("sectional", os.path.join("models","sectional","latest")),
            "use_online": use_online,
        })

        # UIãƒ­ãƒƒã‚¯
        self.btn_run.config(state=tk.DISABLED)
        self.btn_stop.config(state=tk.NORMAL)
        self._log("="*76)
        self._log(f"é–‹å§‹: date={date}, jcd={jcd}, race={race}, approach={approach}")
        self._log(f"model_dir={model_dir or f'models/{approach}/latest'} | CSVãƒ¢ãƒ¼ãƒ‰={'ON' if use_csv else 'OFF'} | è‡ªå‹•æ¨å®š={'ON' if csv_autoguess else 'OFF'} | show_features={'ON' if show_features else 'OFF'} | debug_csv={'ON' if dump_debug else 'OFF'} | online={'ON' if use_online else 'OFF'}")
        self._log("="*76)

        def _worker():
            try:
                self.runner.run_pipeline(
                    date_yyyymmdd=date, jcd=jcd, race=race,
                    approach=approach, model_dir=model_dir,
                    use_online=use_online,
                    use_csv=use_csv, csv_path=csv_path, csv_autoguess=csv_autoguess,
                    show_features=show_features,
                    repo_root=os.getcwd(),
                    dump_debug=dump_debug,
                )
            finally:
                self.btn_run.config(state=tk.NORMAL)
                self.btn_stop.config(state=tk.DISABLED)
                self._log("å®Œäº† / åœæ­¢")

        threading.Thread(target=_worker, daemon=True).start()

    def on_stop(self):
        self.runner.stop()
        self._log("åœæ­¢è¦æ±‚ã‚’é€ä¿¡ã—ã¾ã—ãŸâ€¦")

    def _log(self, msg: str):
        t = datetime.now().strftime("%H:%M:%S")
        self.txt_log.insert(tk.END, f"[{t}] {msg}\n")
        self.txt_log.see(tk.END)

    def _poll_log_queue(self):
        try:
            while True:
                self.txt_log.insert(tk.END, self.log_queue.get_nowait() + "\n")
                self.txt_log.see(tk.END)
        except queue.Empty:
            pass
        finally:
            self.after(50, self._poll_log_queue)


if __name__ == "__main__":
    ensure_parent_dir(SETTINGS_FILE)
    app = App()
    app.mainloop()
